import logging
from antlr4 import *
from generated.lensLexer import lensLexer
from generated.lensParser import lensParser
from ErrorHandler import CustomErrorListener
from SemanticAnalyzer import SemanticAnalyzer
from ASTDotVisitor import ASTDotVisitor
from TACGenerator import TACGenerator
from LLVMIRGenerator import LLVMIRGenerator
import subprocess

# Configura√ß√£o do logging - APENAS para arquivo
logging.basicConfig(
    filename='analisador.log',
    filemode='w',
    encoding='utf-8',
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)

def analisar_arquivo(caminho_arquivo):
    try:
        logging.info(f"Iniciando an√°lise do arquivo: {caminho_arquivo}")

        with open(caminho_arquivo, "r", encoding="utf-8") as f:
            codigo = f.read()

        logging.info("C√≥digo carregado com sucesso.")
        logging.info("Mostrando c√≥digo carregado:")
        logging.info(codigo)
        logging.info("Finalizando exibi√ß√£o do c√≥digo.")

        # ========================================
        # üîç FASE 1: AN√ÅLISE L√âXICA
        # ========================================
        print("\nüîç FASE 1: An√°lise L√©xica")
        logging.info("Iniciando an√°lise l√©xica.")

        input_stream = InputStream(codigo)
        lexer = lensLexer(input_stream)

        error_listener_lexer = CustomErrorListener()
        lexer.removeErrorListeners()
        lexer.addErrorListener(error_listener_lexer)

        token_stream = CommonTokenStream(lexer)
        token_stream.fill()

        with open("lexico.txt", "w", encoding="utf-8") as f_tokens:
            for token in token_stream.tokens:
                token_info = f"{lexer.symbolicNames[token.type]} ('{token.text}') [Linha {token.line}, Coluna {token.column}]"
                f_tokens.write(token_info + "\n")
                logging.info(f"TOKEN: {token_info}")

        if error_listener_lexer.tem_erro:
            logging.warning("Erro l√©xico detectado. Encerrando an√°lise.")
            print("‚ùå Erros l√©xicos encontrados. Encerrando an√°lise.")
            return
        
        print("‚úÖ An√°lise l√©xica conclu√≠da sem erros.")
        print("üìÑ Tokens salvos em 'lexico.txt'.")
        logging.info("An√°lise l√©xica conclu√≠da com sucesso.")

        # ========================================
        # üîç FASE 2: AN√ÅLISE SINT√ÅTICA
        # ========================================
        print("\nüîç FASE 2: An√°lise Sint√°tica")
        logging.info("Iniciando an√°lise sint√°tica.")

        # Criar o parser com o token stream
        parser = lensParser(token_stream)

        error_listener_parser = CustomErrorListener()
        parser.removeErrorListeners()
        parser.addErrorListener(error_listener_parser)

        arvore = parser.lens()

        if error_listener_parser.tem_erro:
            logging.warning("Erro sint√°tico detectado. Encerrando an√°lise.")
            print("‚ùå Erros sint√°ticos encontrados. Encerrando an√°lise.")
            return
        
        print("‚úÖ An√°lise sint√°tica conclu√≠da sem erros.")
        print("üå≥ Gerando AST...")
        
        visitor = ASTDotVisitor()
        visitor.visit(arvore)
        logging.info("AST gerada com sucesso.")

        with open("ast.dot", "w", encoding="utf-8") as f:
            f.write(visitor.get_dot())
        logging.info("Arquivo 'ast.dot' salvo com sucesso.")
        print("‚úÖ Arquivo 'ast.dot' salvo com sucesso.")

        # Tentar gerar imagem PNG da AST
        dot_paths = [
            r"C:\Program Files\Graphviz\bin\dot.exe",
            r"C:\Program Files (x86)\Graphviz\bin\dot.exe",
            "dot"  # Caso esteja no PATH
        ]

        imagem_gerada = False
        for dot_path in dot_paths:
            try:
                subprocess.run([dot_path, "-Tpng", "ast.dot", "-o", "ast.png"], 
                             check=True, capture_output=True, text=True)
                logging.info("Imagem 'ast.png' gerada com sucesso.")
                print("üñºÔ∏è AST gerada com sucesso em 'ast.png'.")
                imagem_gerada = True
                break
            except FileNotFoundError:
                continue
            except subprocess.CalledProcessError as e:
                logging.error(f"Erro ao executar dot: {e.stderr}")
                print("‚ùå Erro ao executar o comando 'dot'. Verifique a sintaxe do arquivo 'ast.dot'.")
                break

        if not imagem_gerada:
            print("‚ö†Ô∏è Graphviz n√£o encontrado. AST salva apenas como .dot")
            print("üí° Instale o Graphviz para gerar imagens: https://graphviz.org/download/")

        logging.info("An√°lise sint√°tica conclu√≠da com sucesso.")

        # ========================================
        # üîç FASE 3: AN√ÅLISE SEM√ÇNTICA
        # ========================================
        print("\nüîç FASE 3: An√°lise Sem√¢ntica")
        
        logging.info("Iniciando an√°lise sem√¢ntica.")
        semantic = SemanticAnalyzer()
        semantic.visit(arvore)
        semantic.report()

        if semantic.errors_found:
            print("‚ùå Erros sem√¢nticos encontrados:")
            print(f"   ‚Ä¢ Consulte 'analisador.log' para detalhes completos")
            print("üìä Tokens e AST foram gerados com sucesso (veja acima).")
            print("\nüõë COMPILA√á√ÉO INTERROMPIDA - C√≥digo n√£o ser√° gerado devido a erros sem√¢nticos.")
            print("üí° Corrija os erros sem√¢nticos e execute novamente.")
            return

        print("‚úÖ An√°lise sem√¢ntica conclu√≠da sem erros.")

        # ========================================
        # üîß FASE 4: GERA√á√ÉO DE C√ìDIGO 
        # ========================================
        print("\nüîß FASE 4: Gera√ß√£o de C√≥digo Intermedi√°rio (TAC)")

        logging.info("Iniciando gera√ß√£o de c√≥digo TAC.")

        tac_generator = TACGenerator()
        tac_generator.visit(arvore)
        tac_generator.save_to_file("output.tac")

        logging.info("Finalizando gera√ß√£o de c√≥digo TAC.")
        logging.info("C√≥digo TAC salvo em 'output.tac'.")

        print("‚úÖ C√≥digo TAC gerado com sucesso.")
        print("‚úÖ C√≥digo TAC salvo em 'output.tac'.")

        # ========================================
        # üîß FASE 5: GERA√á√ÉO DE LLVM IR
        # ========================================
        print("\nüîß FASE 5: Gera√ß√£o de LLVM IR")

        logging.info("Iniciando gera√ß√£o de c√≥digo LLVM IR.")

        llvm_generator = LLVMIRGenerator(tac_generator.instructions)
        llvm_generator.generate()
        llvm_generator.save_to_file("output.ll")

        logging.info("Finalizando gera√ß√£o de c√≥digo LLVM IR.")
        
        print("‚úÖ C√≥digo LLVM IR gerado com sucesso.")
        print("‚úÖ C√≥digo LLVM IR salvo em 'output.ll'.")

        # ========================================
        # üéâ FINALIZA√á√ÉO
        # ========================================
        print("\nüéâ COMPILA√á√ÉO COMPLETA! Pipeline finalizado com sucesso!")
        print("üöÄ Arquivos gerados:")
        print("   ‚Ä¢ analisador.log  - Log detalhado")
        print("   ‚Ä¢ ast.dot/.png    - √Årvore Sint√°tica")
        print("   ‚Ä¢ output.tac      - C√≥digo Intermedi√°rio")
        print("   ‚Ä¢ output.ll       - LLVM IR")

        # ========================================
        # üí° INSTRU√á√ïES DE EXECU√á√ÉO
        # ========================================
        print("\nüí° Instru√ß√µes de execu√ß√£o:")
        print("   clang output.ll -o output.exe")

        print("\nüîß Depend√™ncias necess√°rias:")
        print("   ‚Ä¢ LLVM (clang)")
        print("   ‚Ä¢ MinGW (GCC)")

    except Exception as e:
        logging.exception(f"Erro durante a an√°lise: {e}")
        print(f"‚ùå Erro durante a an√°lise: {e}")

if __name__ == "__main__":
    # caminho = str(input("Digite o nome do arquivo Lens: "))
    caminho = "script"
    analisar_arquivo(f'{caminho}.lens')